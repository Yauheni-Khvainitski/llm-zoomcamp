{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8769909",
   "metadata": {},
   "source": [
    "### Prepare the documents from KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bcba8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "def generate_id(doc):\n",
    "    doc_str = json.dumps(doc, sort_keys=True)  # Convert document to a JSON string\n",
    "    doc_hash = hashlib.md5(doc_str.encode()).hexdigest()  # Generate an MD5 hash\n",
    "    return doc_hash\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        doc_id = generate_id(doc)  # Generate a unique ID for the document\n",
    "        doc['doc_id'] = doc_id  # Add the unique ID as a doc_id key\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6620425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'doc_id': 'bae7a31e6abaddb52b4061dcf238fc61'},\n",
       " {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'doc_id': '3e5d4959603c68a1e154fa2a6bd9d1e8'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd63da2",
   "metadata": {},
   "source": [
    "### Create Elasticsearch index. Load the data from KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c6774f-6d56-4c2f-a89d-12e9416f0518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '0e7ffde126cf', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'RMweVgX3SNqBLG5XOgEriQ', 'version': {'number': '9.0.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '0a58bc1dc7a4ae5412db66624aab968370bd44ce', 'build_date': '2025-05-28T10:06:37.834829258Z', 'build_snapshot': False, 'lucene_version': '10.1.0', 'minimum_wire_compatibility_version': '8.18.0', 'minimum_index_compatibility_version': '8.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "elasticsearch_host = \"http://localhost:9200\"\n",
    "es = Elasticsearch(hosts=elasticsearch_host)\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff554b19-2e2e-4504-81a5-710333ad3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'zoomcamp-courses-questions' does not exist, no need to delete\n",
      "Created index 'zoomcamp-courses-questions': {'acknowledged': True, 'shards_acknowledged': True, 'index': 'zoomcamp-courses-questions'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'zoomcamp-courses-questions'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch.exceptions import NotFoundError, BadRequestError\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"dynamic\": \"strict\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"doc_id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"zoomcamp-courses-questions\"\n",
    "\n",
    "# Delete the existing index if it exists\n",
    "try:\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"Deleted index '{index_name}'\")\n",
    "except NotFoundError as e:\n",
    "    print(f\"Index '{index_name}' does not exist, no need to delete\")\n",
    "except BadRequestError as e:\n",
    "    print(f\"Error deleting index '{index_name}': {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Create the index with the new settings\n",
    "try:\n",
    "    response = es.indices.create(index=index_name, settings=index_settings[\"settings\"], mappings=index_settings[\"mappings\"])\n",
    "    print(f\"Created index '{index_name}': {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index '{index_name}': {e}\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9fd9a7-3b60-435b-ba81-0e0979a72759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ac464d661d4530a90edad2ce1ef67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                       | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 887, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents, ncols = 100):\n",
    "    doc_id = doc[\"doc_id\"]\n",
    "    es.index(index=index_name, id=doc_id, document=doc)\n",
    "\n",
    "es.count(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8a469",
   "metadata": {},
   "source": [
    "## Retrieval (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da2dd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Dict, Any, List\n",
    "from typing import Optional\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "class Course(Enum):\n",
    "    \"\"\"Enum class for available course values.\"\"\"\n",
    "    DATA_ENGINEERING_ZOOMCAMP = \"data-engineering-zoomcamp\"\n",
    "    MACHINE_LEARNING_ZOOMCAMP = \"machine-learning-zoomcamp\"\n",
    "    MLOPS_ZOOMCAMP = \"mlops-zoomcamp\"\n",
    "    LLM_ZOOMCAMP = \"llm-zoomcamp\"\n",
    "\n",
    "def get_es_client() -> Elasticsearch:\n",
    "    \"\"\"\n",
    "    Returns an Elasticsearch client.\n",
    "\n",
    "    Returns:\n",
    "        Elasticsearch: An Elasticsearch client.\n",
    "    \"\"\"\n",
    "    return Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "def set_search_query(\n",
    "    question: str, \n",
    "    course_filter: Optional[Course] = None, \n",
    "    num_results: int = 5, \n",
    "    boost: int = 4\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Set the search query for the Elasticsearch client.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to search for.\n",
    "        course_filter (Optional[Course], optional): The course to filter by (must be from Course enum). \n",
    "                                                   If None, searches across all courses. Defaults to None.\n",
    "        num_results (int, optional): The number of results to return. Defaults to 5.\n",
    "        boost (int, optional): The boost factor for the question. Defaults to 4.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: The Elasticsearch search query dictionary.\n",
    "    \"\"\"\n",
    "    # Build the base query structure\n",
    "    query_structure = {\n",
    "        \"multi_match\": {\n",
    "            \"query\": question,\n",
    "            \"fields\": [f\"question^{boost}\", \"text\", \"section\"],\n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Conditionally add the course filter\n",
    "    if course_filter is not None:\n",
    "        search_query = {\n",
    "            \"size\": num_results,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": query_structure,\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"course\": course_filter.value\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        # No course filter - search across all courses\n",
    "        search_query = {\n",
    "            \"size\": num_results,\n",
    "            \"query\": query_structure\n",
    "        }\n",
    "    \n",
    "    return search_query\n",
    "\n",
    "def search_documents(\n",
    "        search_query: Dict[str, Any],\n",
    "        formatted_docs: bool = True,\n",
    "        index: str = \"zoomcamp-courses-questions\"\n",
    "    ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search documents in Elasticsearch.\n",
    "\n",
    "    Args:\n",
    "        search_query (dict): The search query to execute.\n",
    "        index (str, optional): The index to search in. Defaults to \"zoomcamp-courses-questions\".\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from Elasticsearch.\n",
    "    \"\"\"\n",
    "    es = get_es_client()\n",
    "\n",
    "    response = es.search(index=index, body=search_query)\n",
    "\n",
    "    documents = [hit['_source'] for hit in response['hits']['hits']]\n",
    "\n",
    "    if formatted_docs:\n",
    "        return documents\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81decb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(documents: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Format the documents into a context string.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Dict[str, Any]]): The documents to format.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context string.\n",
    "    \"\"\"\n",
    "    context_template = \"\"\"Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_str = context_template.format(question=doc['question'], text=doc['text'])\n",
    "        context += doc_str + \"\\n\\n\"  # Add double newline between documents\n",
    "\n",
    "    context = context.strip()\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b919218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting set_search_query validation tests...\n",
      "\n",
      "🧪 Testing set_search_query WITH course filter...\n",
      "✅ Test with course filter PASSED\n",
      "🧪 Testing set_search_query WITHOUT course filter...\n",
      "✅ Test without course filter PASSED\n",
      "🧪 Testing set_search_query with different course values...\n",
      "✅ Test with different courses PASSED\n",
      "🧪 Testing set_search_query with default parameters...\n",
      "✅ Test with default parameters PASSED\n",
      "🧪 Testing edge cases...\n",
      "✅ Edge cases test PASSED\n",
      "\n",
      "🎉 ALL TESTS PASSED! The set_search_query function is working correctly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_set_search_query():\n",
    "    \"\"\"\n",
    "    Test suite for the set_search_query function to validate its behavior\n",
    "    with and without course filters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def test_with_course_filter():\n",
    "        \"\"\"Test set_search_query with a course filter.\"\"\"\n",
    "        print(\"🧪 Testing set_search_query WITH course filter...\")\n",
    "        \n",
    "        query = set_search_query(\n",
    "            question=\"How do I copy files to a Docker container?\",\n",
    "            course_filter=Course.MACHINE_LEARNING_ZOOMCAMP,\n",
    "            num_results=3,\n",
    "            boost=4\n",
    "        )\n",
    "        \n",
    "        # Test basic structure\n",
    "        assert isinstance(query, dict), \"Query should be a dictionary\"\n",
    "        assert \"size\" in query, \"Query should have 'size' field\"\n",
    "        assert \"query\" in query, \"Query should have 'query' field\"\n",
    "        \n",
    "        # Test size parameter\n",
    "        assert query[\"size\"] == 3, f\"Expected size 3, got {query['size']}\"\n",
    "        \n",
    "        # Test query structure with course filter\n",
    "        assert \"bool\" in query[\"query\"], \"Query should have 'bool' structure when course filter is provided\"\n",
    "        bool_query = query[\"query\"][\"bool\"]\n",
    "        \n",
    "        assert \"must\" in bool_query, \"Bool query should have 'must' clause\"\n",
    "        assert \"filter\" in bool_query, \"Bool query should have 'filter' clause when course is specified\"\n",
    "        \n",
    "        # Test multi_match structure\n",
    "        multi_match = bool_query[\"must\"][\"multi_match\"]\n",
    "        assert multi_match[\"query\"] == \"How do I copy files to a Docker container?\", \"Question should match input\"\n",
    "        assert \"question^4\" in multi_match[\"fields\"], \"Should boost question field with factor 4\"\n",
    "        assert \"text\" in multi_match[\"fields\"], \"Should include text field\"\n",
    "        assert \"section\" in multi_match[\"fields\"], \"Should include section field\"\n",
    "        assert multi_match[\"type\"] == \"best_fields\", \"Should use best_fields type\"\n",
    "        \n",
    "        # Test course filter\n",
    "        course_filter = bool_query[\"filter\"][\"term\"]\n",
    "        assert course_filter[\"course\"] == \"machine-learning-zoomcamp\", \"Should filter by correct course\"\n",
    "        \n",
    "        print(\"✅ Test with course filter PASSED\")\n",
    "        return True\n",
    "    \n",
    "    def test_without_course_filter():\n",
    "        \"\"\"Test set_search_query without a course filter.\"\"\"\n",
    "        print(\"🧪 Testing set_search_query WITHOUT course filter...\")\n",
    "        \n",
    "        query = set_search_query(\n",
    "            question=\"How do I copy files to a Docker container?\",\n",
    "            num_results=5,\n",
    "            boost=2\n",
    "        )\n",
    "        \n",
    "        # Test basic structure\n",
    "        assert isinstance(query, dict), \"Query should be a dictionary\"\n",
    "        assert \"size\" in query, \"Query should have 'size' field\"\n",
    "        assert \"query\" in query, \"Query should have 'query' field\"\n",
    "        \n",
    "        # Test size parameter (should use default or specified value)\n",
    "        assert query[\"size\"] == 5, f\"Expected size 5, got {query['size']}\"\n",
    "        \n",
    "        # Test query structure without course filter\n",
    "        assert \"multi_match\" in query[\"query\"], \"Query should have direct 'multi_match' when no course filter\"\n",
    "        assert \"bool\" not in query[\"query\"], \"Query should NOT have 'bool' structure when no course filter\"\n",
    "        \n",
    "        # Test multi_match structure\n",
    "        multi_match = query[\"query\"][\"multi_match\"]\n",
    "        assert multi_match[\"query\"] == \"How do I copy files to a Docker container?\", \"Question should match input\"\n",
    "        assert \"question^2\" in multi_match[\"fields\"], \"Should boost question field with factor 2\"\n",
    "        assert \"text\" in multi_match[\"fields\"], \"Should include text field\"\n",
    "        assert \"section\" in multi_match[\"fields\"], \"Should include section field\"\n",
    "        assert multi_match[\"type\"] == \"best_fields\", \"Should use best_fields type\"\n",
    "        \n",
    "        print(\"✅ Test without course filter PASSED\")\n",
    "        return True\n",
    "    \n",
    "    def test_different_courses():\n",
    "        \"\"\"Test set_search_query with different course enum values.\"\"\"\n",
    "        print(\"🧪 Testing set_search_query with different course values...\")\n",
    "        \n",
    "        courses_to_test = [\n",
    "            Course.DATA_ENGINEERING_ZOOMCAMP,\n",
    "            Course.MACHINE_LEARNING_ZOOMCAMP,\n",
    "            Course.MLOPS_ZOOMCAMP,\n",
    "            Course.LLM_ZOOMCAMP\n",
    "        ]\n",
    "        \n",
    "        for course in courses_to_test:\n",
    "            query = set_search_query(\n",
    "                question=\"Test question\",\n",
    "                course_filter=course\n",
    "            )\n",
    "            \n",
    "            # Test that the correct course value is used\n",
    "            expected_course = course.value\n",
    "            actual_course = query[\"query\"][\"bool\"][\"filter\"][\"term\"][\"course\"]\n",
    "            assert actual_course == expected_course, f\"Expected {expected_course}, got {actual_course}\"\n",
    "        \n",
    "        print(\"✅ Test with different courses PASSED\")\n",
    "        return True\n",
    "    \n",
    "    def test_default_parameters():\n",
    "        \"\"\"Test set_search_query with default parameters.\"\"\"\n",
    "        print(\"🧪 Testing set_search_query with default parameters...\")\n",
    "        \n",
    "        query = set_search_query(question=\"Test question\")\n",
    "        \n",
    "        # Should use defaults: course_filter=None, num_results=5, boost=4\n",
    "        assert query[\"size\"] == 5, f\"Expected default size 5, got {query['size']}\"\n",
    "        \n",
    "        # Should not have course filter (direct multi_match)\n",
    "        assert \"multi_match\" in query[\"query\"], \"Should have direct multi_match with defaults\"\n",
    "        \n",
    "        # Should use default boost of 4\n",
    "        fields = query[\"query\"][\"multi_match\"][\"fields\"]\n",
    "        assert \"question^4\" in fields, \"Should use default boost of 4\"\n",
    "        \n",
    "        print(\"✅ Test with default parameters PASSED\")\n",
    "        return True\n",
    "    \n",
    "    def test_edge_cases():\n",
    "        \"\"\"Test edge cases and parameter validation.\"\"\"\n",
    "        print(\"🧪 Testing edge cases...\")\n",
    "        \n",
    "        # Test with empty question\n",
    "        query = set_search_query(question=\"\")\n",
    "        assert query[\"query\"][\"multi_match\"][\"query\"] == \"\", \"Should handle empty question\"\n",
    "        \n",
    "        # Test with very high boost\n",
    "        query = set_search_query(question=\"test\", boost=100)\n",
    "        assert \"question^100\" in query[\"query\"][\"multi_match\"][\"fields\"], \"Should handle high boost values\"\n",
    "        \n",
    "        # Test with very high num_results\n",
    "        query = set_search_query(question=\"test\", num_results=1000)\n",
    "        assert query[\"size\"] == 1000, \"Should handle high num_results values\"\n",
    "        \n",
    "        print(\"✅ Edge cases test PASSED\")\n",
    "        return True\n",
    "    \n",
    "    # Run all tests\n",
    "    print(\"🚀 Starting set_search_query validation tests...\\n\")\n",
    "    \n",
    "    try:\n",
    "        test_with_course_filter()\n",
    "        test_without_course_filter() \n",
    "        test_different_courses()\n",
    "        test_default_parameters()\n",
    "        test_edge_cases()\n",
    "        \n",
    "        print(\"\\n🎉 ALL TESTS PASSED! The set_search_query function is working correctly.\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"\\n❌ TEST FAILED: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n💥 UNEXPECTED ERROR: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the test suite\n",
    "test_set_search_query()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec1cf4",
   "metadata": {},
   "source": [
    "# Augmenting (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e729992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt for the LLM.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to answer.\n",
    "        context (str): The context to use for the answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The prompt for the LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\"\"\".strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "385892c7-96df-49a7-8f41-5f2d36b8c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51ee7f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.10/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fc963b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 320\n",
      "\n",
      "Tokens decoded:\n",
      "63842: You're\n",
      "261:  a\n",
      "4165:  course\n",
      "14029:  teaching\n",
      "29186:  assistant\n",
      "13: .\n",
      "30985:  Answer\n",
      "290:  the\n",
      "150339:  QUESTION\n",
      "4122:  based\n",
      "402:  on\n",
      "290:  the\n",
      "31810:  CONT\n",
      "8099: EXT\n",
      "591:  from\n",
      "290:  the\n",
      "40251:  FAQ\n",
      "7862:  database\n",
      "558: .\n",
      "\n",
      "8470: Use\n",
      "1606:  only\n",
      "290:  the\n",
      "19719:  facts\n",
      "591:  from\n",
      "290:  the\n",
      "31810:  CONT\n",
      "8099: EXT\n",
      "1261:  when\n",
      "55959:  answering\n",
      "290:  the\n",
      "150339:  QUESTION\n",
      "364: .\n",
      "\n",
      "\n",
      "107036: QUESTION\n",
      "25: :\n",
      "3253:  How\n",
      "621:  do\n",
      "5150:  copy\n",
      "261:  a\n",
      "1974:  file\n",
      "316:  to\n",
      "261:  a\n",
      "91238:  Docker\n",
      "9282:  container\n",
      "1715: ?\n",
      "\n",
      "\n",
      "10637: CON\n",
      "50738: TEXT\n",
      "734: :\n",
      "\n",
      "48: Q\n",
      "25: :\n",
      "3253:  How\n",
      "621:  do\n",
      "357:  I\n",
      "15199:  debug\n",
      "261:  a\n",
      "62275:  docker\n",
      "9282:  container\n",
      "3901: ?\n",
      "\n",
      "32: A\n",
      "25: :\n",
      "41281:  Launch\n",
      "290:  the\n",
      "9282:  container\n",
      "3621:  image\n",
      "306:  in\n",
      "25383:  interactive\n",
      "6766:  mode\n",
      "326:  and\n",
      "151187:  overriding\n",
      "290:  the\n",
      "7251:  entry\n",
      "4859: point\n",
      "11: ,\n",
      "813:  so\n",
      "484:  that\n",
      "480:  it\n",
      "13217:  starts\n",
      "261:  a\n",
      "38615:  bash\n",
      "6348:  command\n",
      "558: .\n",
      "\n",
      "68923: docker\n",
      "2461:  run\n",
      "533:  -\n",
      "278: it\n",
      "2230:  --\n",
      "7962: entry\n",
      "4859: point\n",
      "38615:  bash\n",
      "464:  <\n",
      "3365: image\n",
      "523: >\n",
      "\n",
      "3335: If\n",
      "290:  the\n",
      "9282:  container\n",
      "382:  is\n",
      "4279:  already\n",
      "6788:  running\n",
      "11: ,\n",
      "15792:  execute\n",
      "261:  a\n",
      "6348:  command\n",
      "306:  in\n",
      "290:  the\n",
      "4857:  specific\n",
      "9282:  container\n",
      "734: :\n",
      "\n",
      "68923: docker\n",
      "10942:  ps\n",
      "350:  (\n",
      "6555: find\n",
      "290:  the\n",
      "9282:  container\n",
      "26240: -id\n",
      "446: )\n",
      "\n",
      "68923: docker\n",
      "25398:  exec\n",
      "533:  -\n",
      "278: it\n",
      "464:  <\n",
      "6896: container\n",
      "26240: -id\n",
      "29: >\n",
      "38615:  bash\n",
      "198: \n",
      "\n",
      "6103: (M\n",
      "277: ar\n",
      "10732: cos\n",
      "391:  M\n",
      "79771: JD\n",
      "446: )\n",
      "\n",
      "48: Q\n",
      "25: :\n",
      "3253:  How\n",
      "621:  do\n",
      "357:  I\n",
      "5150:  copy\n",
      "6291:  files\n",
      "591:  from\n",
      "922:  my\n",
      "2698:  local\n",
      "7342:  machine\n",
      "316:  to\n",
      "62275:  docker\n",
      "9282:  container\n",
      "3901: ?\n",
      "\n",
      "32: A\n",
      "25: :\n",
      "1608:  You\n",
      "665:  can\n",
      "5150:  copy\n",
      "6291:  files\n",
      "591:  from\n",
      "634:  your\n",
      "2698:  local\n",
      "7342:  machine\n",
      "1511:  into\n",
      "261:  a\n",
      "91238:  Docker\n",
      "9282:  container\n",
      "2360:  using\n",
      "290:  the\n",
      "62275:  docker\n",
      "27776:  cp\n",
      "6348:  command\n",
      "13: .\n",
      "44257:  Here's\n",
      "1495:  how\n",
      "316:  to\n",
      "621:  do\n",
      "480:  it\n",
      "734: :\n",
      "\n",
      "1385: To\n",
      "5150:  copy\n",
      "261:  a\n",
      "1974:  file\n",
      "503:  or\n",
      "12552:  directory\n",
      "591:  from\n",
      "634:  your\n",
      "2698:  local\n",
      "7342:  machine\n",
      "1511:  into\n",
      "261:  a\n",
      "6788:  running\n",
      "91238:  Docker\n",
      "9282:  container\n",
      "11: ,\n",
      "481:  you\n",
      "665:  can\n",
      "1199:  use\n",
      "290:  the\n",
      "2700:  `\n",
      "68923: docker\n",
      "27776:  cp\n",
      "6348:  command\n",
      "62102: `.\n",
      "623:  The\n",
      "9439:  basic\n",
      "45440:  syntax\n",
      "382:  is\n",
      "472:  as\n",
      "18183:  follows\n",
      "734: :\n",
      "\n",
      "68923: docker\n",
      "27776:  cp\n",
      "820:  /\n",
      "4189: path\n",
      "72231: /to\n",
      "52214: /local\n",
      "51766: /file\n",
      "15400: _or\n",
      "35850: _directory\n",
      "9282:  container\n",
      "1537: _id\n",
      "27975: :/\n",
      "4189: path\n",
      "26985: /in\n",
      "190543: /container\n",
      "198: \n",
      "\n",
      "106096: Hr\n",
      "437: ith\n",
      "507: ik\n",
      "70737:  Kumar\n",
      "15241:  Adv\n",
      "3048: ani\n",
      "198: \n",
      "\n",
      "48: Q\n",
      "25: :\n",
      "3253:  How\n",
      "621:  do\n",
      "357:  I\n",
      "5150:  copy\n",
      "6291:  files\n",
      "591:  from\n",
      "261:  a\n",
      "2647:  different\n",
      "15610:  folder\n",
      "1511:  into\n",
      "62275:  docker\n",
      "9282:  container\n",
      "802: ’s\n",
      "4113:  working\n",
      "12552:  directory\n",
      "3901: ?\n",
      "\n",
      "32: A\n",
      "25: :\n",
      "1608:  You\n",
      "665:  can\n",
      "5150:  copy\n",
      "6291:  files\n",
      "591:  from\n",
      "634:  your\n",
      "2698:  local\n",
      "7342:  machine\n",
      "1511:  into\n",
      "261:  a\n",
      "91238:  Docker\n",
      "9282:  container\n",
      "2360:  using\n",
      "290:  the\n",
      "62275:  docker\n",
      "27776:  cp\n",
      "6348:  command\n",
      "13: .\n",
      "44257:  Here's\n",
      "1495:  how\n",
      "316:  to\n",
      "621:  do\n",
      "480:  it\n",
      "734: :\n",
      "\n",
      "637: In\n",
      "290:  the\n",
      "91238:  Docker\n",
      "2318: file\n",
      "11: ,\n",
      "481:  you\n",
      "665:  can\n",
      "3587:  provide\n",
      "290:  the\n",
      "15610:  folder\n",
      "15683:  containing\n",
      "290:  the\n",
      "6291:  files\n",
      "484:  that\n",
      "481:  you\n",
      "1682:  want\n",
      "316:  to\n",
      "5150:  copy\n",
      "1072:  over\n",
      "13: .\n",
      "623:  The\n",
      "9439:  basic\n",
      "45440:  syntax\n",
      "382:  is\n",
      "472:  as\n",
      "18183:  follows\n",
      "734: :\n",
      "\n",
      "128701: COPY\n",
      "9129:  [\"\n",
      "7205: src\n",
      "8138: /p\n",
      "21369: redict\n",
      "17311: .py\n",
      "672: \",\n",
      "392:  \"\n",
      "13123: models\n",
      "22739: /x\n",
      "9320: gb\n",
      "10928: _model\n",
      "69422: .bin\n",
      "672: \",\n",
      "9633:  \"./\n",
      "2601: \"]\n",
      "14973: \t\t\t\t\t\t\t\t\t\t\n",
      "22713: \tG\n",
      "167296: opak\n",
      "30463: umar\n",
      "499:  G\n",
      "137058: opin\n",
      "22064: athan\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "\n",
    "print(f\"Number of tokens: {len(tokens)}\\n\")\n",
    "\n",
    "print(f\"Tokens decoded:\")\n",
    "for token in tokens:\n",
    "    print(f\"{token}: {encoding.decode([token])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "663628dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can copy files from your local machine into a Docker container using the `docker cp` command. The basic syntax is:\n",
      "\n",
      "```bash\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "env_file_path = \".env\"\n",
    "load_dotenv(dotenv_path=env_file_path, verbose=True, override=True)\n",
    "\n",
    "open_ai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=open_ai_api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13c144aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $2.88\n"
     ]
    }
   ],
   "source": [
    "input_price_per_token_gpt_4o = 2.5/1000000\n",
    "output_price_per_token_gpt_4o = 10/1000000\n",
    "num_requests = 1000\n",
    "avg_per_request_tokens = 150\n",
    "avg_output_tokens = 250\n",
    "\n",
    "total_cost = (num_requests * avg_per_request_tokens * input_price_per_token_gpt_4o + num_requests * avg_output_tokens * output_price_per_token_gpt_4o)\n",
    "\n",
    "print(f\"Total cost: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd83982",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a84884",
   "metadata": {},
   "source": [
    "### Q3. Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c7439fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.50556\n"
     ]
    }
   ],
   "source": [
    "question = \"How do execute a command on a Kubernetes pod?\"\n",
    "\n",
    "search_query = set_search_query(question=question)\n",
    "\n",
    "results = search_documents(search_query, formatted_docs=False)\n",
    "\n",
    "print(results['hits']['max_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d24ef",
   "metadata": {},
   "source": [
    "### Q4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58a42f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n"
     ]
    }
   ],
   "source": [
    "question = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "search_query = set_search_query(question=question, course_filter=Course.MACHINE_LEARNING_ZOOMCAMP, num_results=3, boost=4)\n",
    "\n",
    "results = search_documents(search_query)\n",
    "\n",
    "print(results[2]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25017c3f",
   "metadata": {},
   "source": [
    "### Q5. Building a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86b7a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1462\n",
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "    QUESTION: How do copy a file to a Docker container?\n",
      "\n",
      "    CONTEXT:\n",
      "    Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n"
     ]
    }
   ],
   "source": [
    "context = format_context(results)\n",
    "\n",
    "prompt = build_prompt(question=question, context=context)\n",
    "\n",
    "print(len(prompt))\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
